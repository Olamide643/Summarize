{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import requests\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize , sent_tokenize \n",
    "import heapq\n",
    "from flask import Flask, jsonify, render_template, request\n",
    "import pickle \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the models \n",
    "model = load_model(\"Sentiment_Analysis_on_TR\")\n",
    "with open('tokenize.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:800/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [19/Nov/2020 13:26:54] \"\u001b[31m\u001b[1mGET / HTTP/1.1\u001b[0m\" 405 -\n",
      "127.0.0.1 - - [19/Nov/2020 13:26:54] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [19/Nov/2020 13:27:13] \"\u001b[31m\u001b[1mGET / HTTP/1.1\u001b[0m\" 405 -\n",
      "127.0.0.1 - - [19/Nov/2020 13:27:53] \"\u001b[31m\u001b[1mGET / HTTP/1.1\u001b[0m\" 405 -\n",
      "127.0.0.1 - - [19/Nov/2020 13:32:20] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "@app.route('/', methods = ['POST'])\n",
    "def classify():\n",
    "    Request = request.get_json()\n",
    "    url = Request['url']\n",
    "    id = Request['id']\n",
    "    \n",
    "    full_path = url + str(id) \n",
    "    response = requests.get(full_path)\n",
    "    code = response.status_code\n",
    "    if (code == 404):\n",
    "        Data ={\"Code:\":code, \"message\":\"Not found\"}\n",
    "\n",
    "    elif (code == 500):\n",
    "        Data = {\"Code:\":code, \"message\":\"Internal Server Error\"}\n",
    "\n",
    "    elif (code == 400):\n",
    "        Data = {\"Code:\":code, \"message\":\"Bad Request\"}\n",
    "\n",
    "    elif (code == 200):\n",
    "        user_res = response.json()\n",
    "        user = response.json()['blog']['userId']\n",
    "        blog= response.json()['blog']\n",
    "        \n",
    "        content = blog['content']\n",
    "        title = blog['title']\n",
    "        author = user['fullName']\n",
    "        Date_created = blog['createdAt'][0:10]\n",
    "        Time_Created = blog['createdAt'][11:19]\n",
    "        Last_Updated = blog['updatedAt'][0:10]\n",
    "        Lime_Updated = blog['updatedAt'][11:19]\n",
    "\n",
    "    \n",
    "        text_ = content.lower()\n",
    "        Stopwords = set(stopwords.words('english'))\n",
    "        word_freq = {}\n",
    "        for word in word_tokenize(text_):\n",
    "            if word not in Stopwords:\n",
    "                if word not in word_freq.keys():\n",
    "                    word_freq[word] = 1 \n",
    "                else:\n",
    "                    word_freq[word] +=1\n",
    "        max_freq = max(word_freq.values())\n",
    "    \n",
    "        for word in word_freq:\n",
    "            word_freq[word] = word_freq[word]/max_freq\n",
    "    \n",
    "        sent_list = sent_tokenize(text_)\n",
    "        sent_scores ={}\n",
    "        for sent in sent_list:\n",
    "            for word in word_tokenize(sent.lower()):\n",
    "                if word in word_freq.keys():\n",
    "                    if len(sent.split(' '))<30:\n",
    "                        if sent not in sent_scores.keys():\n",
    "                            sent_scores[sent] = word_freq[word]\n",
    "                        else:\n",
    "                            sent_scores[sent] += word_freq[word]\n",
    "        summary_sentences = heapq.nlargest(10, sent_scores, key = sent_scores.get)\n",
    "        Cap_sent=[]\n",
    "        for tex in summary_sentences:\n",
    "            tex_cap = tex.capitalize()\n",
    "            Cap_sent.append(tex_cap)\n",
    "        summary = \" \".join(Cap_sent)\n",
    " \n",
    "        text = content\n",
    "        text_list = [text]\n",
    "        text_token = tokenizer.texts_to_sequences(text_list)\n",
    "        text_pad = pad_sequences(text_token, maxlen = 241, padding = 'pre')\n",
    "        pred = model.predict(text_pad)\n",
    "        if pred[0][0] > 0.5:\n",
    "            result = \"Positive Review!\"\n",
    "            per = round((pred[0][0])*100 , 2)\n",
    "\n",
    "        else:\n",
    "            result = 'Negative Review! '\n",
    "            per = round((pred[0][0])*100,2) \n",
    "        Data = {'Title':title, 'Author':author,\"Date_created\":Date_created,\n",
    "            'Time_Created':Time_Created, 'Summmary' : summary,\n",
    "            'Last_Updated':Last_Updated, 'Lime_Updated':Lime_Updated,\n",
    "            'Sentiment' : result, 'Certainity_Percentage': per, 'Contnt':content}\n",
    "    elif (code == 401):\n",
    "        Data ={\"Code:\":code, \"message\":\"Unauthorized\"}\n",
    "\n",
    "    else: \n",
    "        Data ={\"Code:\":code, \"message\":\"Not found\"}\n",
    "    return jsonify(Data)\n",
    "\n",
    "if __name__ =='__main__':\n",
    "     app.run(port = 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
